{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_style(style=\"whitegrid\")\n",
    "sb.set_color_codes()\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import eif_old as eif_old_class\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlike-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mammography\"\n",
    "dataset_type = \"origin\"\n",
    "# # parameter for traing the forest\n",
    "number_of_trees = 100\n",
    "subsample_size = 256\n",
    "extensionLevel = 0\n",
    "rng = np.random.RandomState(53)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pursuant-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('./datasets/' + dataset_name + '.mat')\n",
    "np_x_data = np.array(data[\"X\"])\n",
    "np_y_data = np.array(data[\"y\"])\n",
    "np_x_y_data = np.concatenate((np_x_data, np_y_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documentary-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(n_estimators=number_of_trees, max_samples=subsample_size, random_state=rng,\n",
    "                      contamination='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mysterious-poster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(max_samples=256,\n",
       "                random_state=RandomState(MT19937) at 0x1C93B565D40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mysterious-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sif = clf.predict(np_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sunset-fraud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ..., -1,  1, -1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worldwide-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sif = np.where(y_pred_sif == 1, 0, y_pred_sif)\n",
    "y_pred_sif = np.where(y_pred_sif == -1, 1, y_pred_sif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "small-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_decision_func_sif = clf.decision_function(np_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "facial-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06103821,  0.07090384, -0.09937924, ..., -0.14901627,\n",
       "        0.06187326, -0.11511414])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_decision_func_sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "weighted-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_sif = clf.score_samples(np_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "instructional-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56103821, -0.42909616, -0.59937924, ..., -0.64901627,\n",
       "       -0.43812674, -0.61511414])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score_sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "african-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_sif_abs = abs(clf.score_samples(np_x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "assigned-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56103821, 0.42909616, 0.59937924, ..., 0.64901627, 0.43812674,\n",
       "       0.61511414])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score_sif_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "animal-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_sif_neg = - clf.score_samples(np_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "novel-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56103821, 0.42909616, 0.59937924, ..., 0.64901627, 0.43812674,\n",
       "       0.61511414])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score_sif_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sexual-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = y_score_sif_neg == y_score_sif_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vietnamese-shanghai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "clinical-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_value = skm.roc_auc_score(np_y_data, y_score_sif_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "golden-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501612687413292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-halloween",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-abuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-training",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-burden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-battery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-juice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-newman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-spectacular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-union",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-honey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-sampling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-picking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-ribbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-illness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-unemployment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-entity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-identifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-index",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-sandwich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-discretion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-tracker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-instrument",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-restoration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-george",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-rider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-split",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-algebra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-fight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-orbit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-tutorial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-waters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-obligation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
